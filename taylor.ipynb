{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100000\n",
    "sample_dim = 10\n",
    "noise_scale = 1.0\n",
    "train_split = 0.8\n",
    "theta_range = 1.0\n",
    "data_range = 500\n",
    "epoch = 50000\n",
    "lr = 1e-5\n",
    "dim_per_task = 7\n",
    "task_num = 10\n",
    "shift_scale = 1e-8\n",
    "tasks = [np.random.randint(0, sample_dim, dim_per_task) for _ in range(task_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGen:\n",
    "    def __init__(self, sample_size, sample_dim, noise_scale, train_split, theta_range, data_range, tasks):\n",
    "        self.sample_size = sample_size\n",
    "        self.sample_dim = sample_dim\n",
    "        self.noise_scale = noise_scale\n",
    "        self.train_split = train_split\n",
    "        self.theta_range = theta_range\n",
    "        self.data_range = data_range\n",
    "        self.theta = np.random.uniform(-theta_range, theta_range, (sample_dim, 1))\n",
    "        self.tasks = tasks\n",
    "    \n",
    "    def get_data(self):\n",
    "        for task in self.tasks:\n",
    "            self.theta += shift_scale*self.noise_scale*np.random.normal(0, 1, (self.sample_dim, 1))\n",
    "            X = np.zeros((self.sample_size, self.sample_dim))\n",
    "            X[:, task] = np.random.uniform(-self.data_range, self.data_range, (self.sample_size, self.sample_dim))[:, task]\n",
    "            y = np.dot(X, self.theta).squeeze() + self.noise_scale * np.random.normal(0, 1, self.sample_size)\n",
    "            train_size = int(self.sample_size * self.train_split)\n",
    "            X_train, X_test = torch.tensor(X[:train_size], dtype=torch.float), torch.tensor(X[train_size:], dtype=torch.float)\n",
    "            y_train, y_test = torch.tensor(y[:train_size], dtype=torch.float), torch.tensor(y[train_size:], dtype=torch.float)\n",
    "            yield X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, sample_dim, lr):\n",
    "        super().__init__()\n",
    "        self.theta = torch.nn.Parameter(torch.randn(sample_dim, 1))\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=lr)\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "    \n",
    "    def set_data(self, X, y):\n",
    "        self.X, self.y = X.detach().clone(), y.detach().clone()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return torch.matmul(X, self.theta).squeeze()\n",
    "    \n",
    "    def train(self, X, y, epoch, lr):\n",
    "        for _ in range(epoch):\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.loss_fn(self(X), y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "    \n",
    "    def test(self, X, y):\n",
    "        return self.loss_fn(self(X), y)\n",
    "    \n",
    "    def get_loss_with_theta(self, theta):\n",
    "        return self.loss_fn(torch.matmul(self.X, theta).squeeze(), self.y)\n",
    "    \n",
    "    def get_gradient(self, X, y, theta):\n",
    "        self.set_data(X, y)\n",
    "        return autograd.functional.jacobian(self.get_loss_with_theta, theta.squeeze()).detach().clone()\n",
    "    \n",
    "    def get_hessian(self, X, y, theta):\n",
    "        self.set_data(X, y)\n",
    "        return autograd.functional.hessian(self.get_loss_with_theta, theta.squeeze()).detach().clone()\n",
    "    \n",
    "    def prepare_estimation(self, X, y, old_theta):\n",
    "        self.gradient = self.get_gradient(X, y, old_theta).reshape(1, -1)\n",
    "        self.hessian = self.get_hessian(X, y, old_theta)\n",
    "        self.old_theta = old_theta.detach().clone()\n",
    "        self.old_ans = self.get_loss_with_theta(old_theta).detach().clone()\n",
    "    \n",
    "    def estimate(self, theta):\n",
    "        dtheta = theta - self.old_theta\n",
    "        ans = self.old_ans.detach().clone()\n",
    "        ans += torch.matmul(self.gradient, dtheta).squeeze()\n",
    "        ans += 0.5 * torch.matmul(torch.matmul(dtheta.T, self.hessian), dtheta).squeeze()\n",
    "        return ans\n",
    "    \n",
    "    def diag_estimate(self, theta):\n",
    "        dtheta = theta - self.old_theta\n",
    "        ans = self.old_ans.detach().clone()\n",
    "        ans += torch.matmul(self.gradient, dtheta).squeeze()\n",
    "        ans += 0.5 * torch.dot(torch.diag(self.hessian),(dtheta.squeeze())).squeeze()\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation: 1.0073801279067993, Actual: 1.0073801279067993, Change Ratio: 0.0\n",
      "Diag Estimation: 3.13822078704834, Change Ratio: 2.1152299912537895\n",
      "Estimation: 1.0062575340270996, Actual: 1.0062580108642578, Change Ratio: 4.7387166418042e-07\n",
      "Diag Estimation: -5.9083099365234375, Change Ratio: 6.871565615113853\n",
      "Estimation: 1.0045831203460693, Actual: 1.0045832395553589, Change Ratio: 1.1866541751537163e-07\n",
      "Diag Estimation: 7.205212593078613, Change Ratio: 6.172340040500507\n",
      "Estimation: 1.0042859315872192, Actual: 1.0042853355407715, Change Ratio: 5.935030878778656e-07\n",
      "Diag Estimation: -1.6709250211715698, Change Ratio: 2.663795100893151\n",
      "Estimation: 0.9961096048355103, Actual: 0.9961095452308655, Change Ratio: 5.983743962776326e-08\n",
      "Diag Estimation: -1.8846137523651123, Change Ratio: 2.8919743931660857\n",
      "Estimation: 0.9923503398895264, Actual: 0.9923505783081055, Change Ratio: 2.402564016318215e-07\n",
      "Diag Estimation: -0.02004152536392212, Change Ratio: 1.0201960131852714\n",
      "Estimation: 0.9970933794975281, Actual: 0.9970933794975281, Change Ratio: 0.0\n",
      "Diag Estimation: 9.001769065856934, Change Ratio: 8.02801006500841\n",
      "Estimation: 1.0005348920822144, Actual: 1.0005348920822144, Change Ratio: 0.0\n",
      "Diag Estimation: -2.84512996673584, Change Ratio: 3.8436089428274074\n",
      "Estimation: 0.9976611137390137, Actual: 0.9976604580879211, Change Ratio: 6.57188612833161e-07\n",
      "Diag Estimation: -3.5708255767822266, Change Ratio: 4.579199263470798\n"
     ]
    }
   ],
   "source": [
    "model = Model(sample_dim, lr)\n",
    "Data = DataGen(sample_size, sample_dim, noise_scale, train_split, theta_range, data_range, tasks)\n",
    "first_task = True\n",
    "for X_train, y_train, X_test, y_test in Data.get_data():\n",
    "    model.train(X_train, y_train, epoch, lr)\n",
    "    if first_task:\n",
    "        first_task = False\n",
    "    else:\n",
    "        estimation = float(model.estimate(model.theta))\n",
    "        diag_estimation = float(model.diag_estimate(model.theta))\n",
    "        actual = float(model.test(model.X, model.y))\n",
    "        delta = float(np.abs(estimation - actual))\n",
    "        print(f\"Estimation: {estimation}, Actual: {actual}, Change Ratio: {delta/actual}\")\n",
    "        delta = float(np.abs(diag_estimation - actual))\n",
    "        print(f\"Diag Estimation: {diag_estimation}, Change Ratio: {delta/actual}\")\n",
    "    model.prepare_estimation(X_train, y_train, model.theta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ewc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75bcbc7ecb8809637fbec3e0f1b4e88beb1d0779e970f7f640759102f9000d4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
